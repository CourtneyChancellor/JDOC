\documentclass[en]{jdoc}
\include{macros-ph}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{tikz}
\usetikzlibrary{fit}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning}
\usepackage{stmaryrd}


\ed{PRES LUNAM \\ École Doctorale STIM \\ Sciences et Technologies de l'Information
et Mathématiques}
\spec{BioInformatics}
\labo{IRCCyN}
\equipe{MeForBio}
\title{Addressing Qualitative Models Gene Regulatory Networks with Numerical Tools}
\author{Courtney Chancellor}
\email{Courtney.Chancellor@ec-nantes.fr}


\begin{document}

\makehead
 
 \begin{abstract}
 Our ability to gather data in the context of \textit{gene regulatory networks} has skyrocketed in the past decades, 
the scale of which is massive and uninterpretable without applying formal analysis. \textit{Qualitative modeling} techniques are commonly used in this context as they are able to scale up with large, interconnected graphs with high degrees of abstraction. Analysis, however, may be limited to the questions and tools which do not require the construction of the full state space, which grows exponentially. By addressing these models with numerical tools capable of solving \textit{high-dimensional problems}, we are able to directly access the probability of the system occupying any state at any given time.
\end{abstract}

\begin{keywords}
 genetic regulation, 
 qualitative modeling, 
 high dimensional systems, 
 numerical methods
\end{keywords}

\begin{collaborations}
Francisco Chinesta,
Morgan Magnin,
Olivier Roux
\end{collaborations}

\section{Introduction}

  A large part of bioinformatics is dedicated to the modeling of biological systems with the hopes of supplementing experimental work or informing experimental design. Many modeling frameworks exist, each of which brings its own strengths and weaknesses, data requirements and fundamental assumptions. As a result, what kind of framework to choose is largely informed by the characteristics of the system or the nature of the information we wish to derive from our model. For regulation of genetic expression, qualitative modeling schemes can be advantageous as they are well suited for handling the very large, interconnected graph of interacting species typical of these systems. However, in exchange for being scalable, qualitative models contain less detail and typically give limited access to the underlying probability distribution of the state space. To do so normally requires simulation techniques. In our work, we attempt to apply numerical methods to qualitative systems in order to directly access this probability distribution, deepening our potential to analyze very large, or high dimensional, systems. We begin by taking a Process Hitting \cite{FPIMR12-CMSB, pauleve2011tuning} model, a qualitative modeling framework which demonstrates excellent scalability and possesses several efficient analysis tools. Although many possible options exist, we will briefly investigate two numerical methods of particular interest in our work: Proper Generalized Decomposition and Moment Closure.
  
  \section{Qualitative Models and Process Hitting}
  
  Typically, we are given an initial description of a biological system such as ``gene A activates gene B after passing some threshold value.''(Figure \ref{PH_fig}, middle) This is quite different than kinetic models, which generally demonstrate mass action rate laws: ``two molecules of A combine with one molecule of B to produce C at rate r'', which are treated with quantitative frameworks. The network of influence between genes is called the \textit{regulatory network} and is commonly represented as a directed, signed graph (Figure \ref{PH_fig}, left). Qualitative frameworks attempt to use this information to construct functional models of a given system in order to perform in-depth analysis or \textit{in silico} experiments. Process Hitting is one of many possible qualitative approaches. This technique abstractly represents all participating elements of a network, albeit genes, proteins or environmental factors, as automata. These automata possess local states (on/off, low/medium/high concentrations, etc) which interact with one another to asychronously and non deterministically move the system from one state to another. Such interactions are divided into two parts: the initial influence and the resulting transition (Figure \ref{PH_fig}, right). The translation of a directed graph to Process Hitting is relatively straightforward.
   \begin{figure}[h]
\begin{subfigure}[t]{0.3\textwidth}
   \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
  thick,main node/.style={circle,fill=blue!20,draw,font=\sffamily\Large\bfseries}]
  \node[main node] (a) {a};
  \node[main node] (b) [right of=a] {b};
  \path[->,>=angle 90]
(a) edge node[above]{$+$} (b);
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}[b]{0.35\textwidth}
\resizebox{.9\textwidth}{!}{
 \begin{tikzpicture}[scale=2]
  \draw (-1,0) rectangle (1,1);
  \node [rotate=90] at (-1.25,.5) {\% of effect};
    \node [bottom] at (0,-.25) {concentration of activator};

  \draw [red] (0,0) -- (0,1);
    \foreach \x in {-1,-0.75,...,1}{
      \draw[y=1cm,thick,blue] (\x,0) -- (\x,-0.1);
      ;
    }
    \foreach \y in {0.5,1}{
      \draw[thick,blue] (0,\y) -- (-0.2,\y);
      \node at (-0.45,\y) {\y};
    }
    \coordinate (a) at (1,1);
    \coordinate (b) at (-1,0);
    \draw (b) edge[ultra thick,out=360,in=180,looseness = 2.25] (a);    
  \end{tikzpicture}}
  \end{subfigure}
\begin{subfigure}[b]{0.33\textwidth}
\begin{tikzpicture}
\TSort{(0,0)}{a}{2}{l}
\TSort{(2,0)}{b}{2}{r}
\THit{a_1}{}{b_0}{.west}{b_1}
\path[bounce, bend left]
\TBounce{b_0}{}{b_1}{.south};
\THit{a_0}{}{b_1}{.west}{b_0}
\path[bounce, bend right]
\TBounce{b_1}{}{b_0}{.north};
\end{tikzpicture}
\end{subfigure}

\caption{Creating a Process Hitting action. In gene regulation, we consider two kinds of interactions between species: activation and inhibition. If $a$ is an activator of $b$, it is common to represent this by a signed, directed graph (left). These interactions have a characteristic form: unlike kinetic reactions, activation and inhibition usually depend on the regulator passing some threshold concentration in order to become effective (middle). The genes $a$ and $b$ are represented as automata with two local states, $0$ and $1$, representing ``present'' and ``absent'', respectively. A Process Hitting translation of the reaction $a$ activates $b$ is seen on the right as $a_1$ interacts with $b_0$ (solid arrow) to make $b$ transition (bashed arc) to $b_1$. Unless we have additional information about the network, generally, we model what is known as the \textemph{generalized dynamics} of the system, or the most permissive dynamics possible given an interaction graph. In a practical sense, this means that the absence of an activator is effectively an inhibition and that the absence of an inhibitor is effectively an activator. Therefore, we add the interaction $a_0$ interacts with $b_1$ to make $b$ transition to $b_0$, as well. Every action can be associated with temporal and stochastic parameters- the reaction rate, for example.}
\label{PH_fig}
\end{figure}
Although this is a highly abstract representation of a biological process, Process Hitting semantics allow us to easily model interactions with only partial knowledge of the system as a whole. For example, it is sufficient to know that one gene inhibits another, without knowing the exact mechanism therein. Furthermore, Process Hitting possesses powerful static analysis techniques in order to study steady state behavior, the reachability of a certain state from another, and cut sets which determine minimum criteria for reachability, all of which are done without the need of constructing the full state space, making it a very scalable framework. Models of up to 10,000 interacting species have been successfully addressed using Process Hitting. However, this analysis is somewhat limited in scope. To answer deeper, more nuanced questions of the model, we must be able to access the full solution space, the probability of the system existing at any state, $z$, at a given time, $t$, or $\Phi(z,t)$. This probability distribution can be accessed via the Markov Jump Equations of the model which track the net change in probability as the system between states $z$ to $z\prime$ through time given that these transitions happen with propensity $a(z,t)$.
\[
\frac{\partial \Phi(z,t)}{\partial t} = \sum_j  a_j(z\prime,t)\Phi(z\prime,t) -\sum_k a_k(z,t)\Phi(z,t)
\]
While using these equations for simulation have been historically prevalent, the application of numerical techniques has the potential to do the same but without computationally prohibitive trial runs.
\section{Numerical Techniques}
\subsection{Proper Generalized Decomposition}
Proper Generalized Decomposition \cite{chinesta2011overview,chinesta2010use} is a reduced basis technique which assumes that the target, in this case, the probability distribution, can be written as a sum of a product of separable functions of the interacting species, $F(z_i)$ $i=\{1\cdots N_{sp}\}$, and time, $F(t)$:
\[
 \Phi(z,t)\cong \sum_{j=1}^{M}F_1^j(z_1)\cdots F_2^j(z_2)\cdots F_{N_{sp}}^j(z_{N_{sp}}) \cdot F_t(t)
\]
PGD is performed iteratively, starting at some arbitrary guess and searching for sets of functions, one vector at a time, which will minimize the residual of the running sum. Although the accuracy increases with every addition, we assume that only a limited number, $M$, of sets of functions are needed to capture the behavior of the system. We have not changed the state space but, rather, re-ordered it such that only one $N\times1$ vector, usually on the scale of 2 or 3 since this size represents the possible local states of a qualitative model, must be addressed at any given time, see Figure \ref{cubes}. This dramatically increases the potential size and complexity of model that can be addressed, even in circumstances in which simulation techniques would be prohibitively slow. All operations can be performed by canonical techniques and are highly parallelizable, therefore iterations are generally fast and computationally inexpensive. In addition, the form of PGD offers a natural way of handling unknown parameters by incorporating them as additional state space dimensions without changing the original algorithm. This, in particular, is a very desirable characteristic for application to biological regulatory networks since many parameters are often either unknown or come with some degree of uncertainty.
\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=0.5]

  \draw[yslant=-0.5] (0,0) grid (3,3);

  \draw[yslant=0.5] (3,-3) grid (6,0);
  \draw[yslant=0.5,xslant=-1] (3,0) grid (6,3);
  
  \draw [->,red,ultra thick] (7.5,1.5) -- (8.5,1.5);
  \draw (10,0) grid (11,3);
  \node[scale=2] at (12,1.5) {$\times$};
  \draw (13,0) grid (14,3);
    \node[scale=2] at (15,1.5) {$\times$};
  \draw (16,0) grid (17,3);
\end{tikzpicture}
\caption{Decomposition of a state space. This illustration shows how a multidimensional space, for example, a cubic space of three dimensions, $3^3$ can be decomposed into the product of the individual dimensions, $3\times 3$. This mathematical property is exploited by PGD in that we search for sets of $N_{sp}$ $(1\times N)$ vectors  which are relatively small compared to the full $N_{sp}^N$ state space. Repeated $M$ times such that each new set minimizes the residual, the results are summed to produce the final approximation.}
\label{cubes}
\end{figure}
\subsection{Moments and Moment Closure}
Until now, we have ignored the fact that $P$ is a probability distribution: we have focused on finding a solution, or a ``fit'' to the equation for $\frac{\partial \Psi(z,t)}{\partial t}$, without asking ourselves about certain properties that we expect our solution to have or what interests us about our solution. A probability distribution is uniquely defined by its full set of \textemph{moments}, and sometimes it is more conveniant or informative to talk about a system's moments-- the mean or the covariance between two particular elements, for instance-- than the contour of the probability distribution itself \cite{milner2011moment}. A moment is, quite simply, the expected value of a random variable, $z$, raised to a certain power. In general, we can talk about the $i$th moment of discrete spaces as:

$$ \mu_i (t) = E\left[ z^i \right] = \sum_{z=0}^\infty P(z,t) z^i$$

If we are most interested in finding these moments for the system, the moment generating function is a function whose properties are inherently linked to moments of a probability distribution.
$$M(\theta, t)=\sum_{z=0}^\infty e^{\theta z} P(z,t)=\sum_{z=0}^\infty \frac{\mu_z(t)\theta^z}{z!}$$
By rewriting the Markov Equations for $\Psi$ such that they are defined in terms of $M$, we will be able to generate a system of equations for the desired moments of the system. However, these systems of equations result in a systems of equations in which each moment depends on some moments higher than itself, or $\mu_i$ is dependent on $\mu_{i+1}$, $\mu_{i+1}$ is dependent on $\mu_{i+2}$, and so on. At this point, we must \textit{close} the sequence of moments such that the resulting system is solvable. Because this represents a simplification, there will always be some information lost by moment closure. However, the resulting moments may be sufficient to fully describe the dynamics of interest and the structure of this problem formulation does not demonstrate the same curse of dimensionality.
There exist several methods for moment closure, although the majority of them can be described as \textbf{matching-based} ( e.g. writing higher order moments in terms of lower moments), \textbf{distribution-based} (e.g. setting moments higher than the second to 0 to result in a normal distribution) or \textbf{large volume} methods (e.g. assuming reactions are nearly deterministic in that probabilities are tightly distributed around their means). The goodness of these choses depend wholly on what the modeler can say about his network and remain a very subjective, case-by-case measure.

\section{Concluding Remarks}
Qualitative modeling can be highly advantageous in the domain of geonomics given the characteristic features of the systems normally encountered. Although many such modeling frameworks exist, Process Hitting has demonstrated exceptional abilities to scale with the number of incorporated elements, or nodes in the interation network. While some of the most critical analyses can be done without the need of an underlying probability distribution, not all questions can be fully answered without it. We have briefly touched on two ways of numerically approaching qualitative modeling schemes via their corresponding Markov equations. The application of Proper Generalized Distribution quickly obtains approximations of the probability distribution as a whole, while a search for moments using Moment Closure schemes may produce the most vital peices of information. Each of these methods have its advantages and disadvantages, and, as of yet, we are not able to generalize on what might be the best overall approach for arbitrary networks. Investigating this particular aspect is our current avenue of research, a topic which will follow us through the upcomming years.
\bibliography{biblio-en}

\end{document}
